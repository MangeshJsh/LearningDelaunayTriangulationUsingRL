{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654336745098,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "NOZzAJuD1FqK",
    "outputId": "954ad357-9bee-4b61-bf5c-846239fcbc9d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False\n",
    "\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3661,
     "status": "ok",
     "timestamp": 1654336748756,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "QtwAzGXgrBzy",
    "outputId": "ab052888-c71a-49bd-ac7f-80f1228d09fb"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  # Mount the Google Drive at mount\n",
    "  mount='/content/drive'\n",
    "  print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "  drive.mount(mount)\n",
    "\n",
    "  # Switch to the directory on the Google Drive that you want to use\n",
    "  import os\n",
    "  drive_root = mount + \"/My Drive/Thesis_coding_with_IAE\"\n",
    "  \n",
    "  # Change to the directory\n",
    "  print(\"\\nColab: Changing directory to \", drive_root)\n",
    "  %cd $drive_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5192,
     "status": "ok",
     "timestamp": 1654336753944,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "xneW-W9f5P-7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CommonDefs import Point, Edge \n",
    "from TwoDimConvexHull import TwoDimConvexHull, PrintTwoDimConvexHull\n",
    "from Utils import nearestKNeighboursOfEdgeMidPt, checkTriangleForDelaunayCriteria\n",
    "from Graph import Graph\n",
    "from DTEnv import DTEnv\n",
    "from DTDoubleDQNAgent import DTDoubleDQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1654336753945,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "xBA7umXd5P-_"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1654336753945,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "kDUsGg4K5P-_"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1654336753946,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "quXizeJE5P_A"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1654336753947,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "02urf76A5P_A",
    "outputId": "9b9951a8-7988-4344-9cc4-17d20f77338c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\Thesis_Experiments\\Data\\DT_5_sorted.txt\", sep=\" \", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1654336753947,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "zL-HBka0zGTQ",
    "outputId": "82de87bc-04b4-4736-f775-7b6e3dfddc22"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1654336753948,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "c9WkLEqg5P_A"
   },
   "outputs": [],
   "source": [
    "pointData = {}\n",
    "for i in range(len(df)):\n",
    "    pointId = 1\n",
    "    points = []\n",
    "    for j in range(0 , len(df.columns), 2):\n",
    "        if df.loc[i, j] == \"output\":\n",
    "            dtStartIdx = j + 1\n",
    "            break\n",
    "        else:\n",
    "            points.append(Point(pointId, df.loc[i, j], df.loc[i, j + 1]))\n",
    "            pointId = pointId + 1\n",
    "    pointData[i] = points\n",
    "\n",
    "#for key, value in pointData.items():\n",
    "    #print('key: {}, value: {}'.format(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1654336753949,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "WIdg8AOf5P_B"
   },
   "outputs": [],
   "source": [
    "# Initialising the environment\n",
    "env = DTEnv()\n",
    "\n",
    "agent = DTDoubleDQNAgent(env)\n",
    "\n",
    "# tracking average reward per episode = total rewards in an episode/ total steps in an episode\n",
    "avg_reward = []\n",
    "\n",
    "# tracking total rewards per episode\n",
    "total_reward  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1654336753950,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "IHzqp3Wt5P_C"
   },
   "outputs": [],
   "source": [
    "states_track = collections.defaultdict(dict)\n",
    "def initialise_tracking_states(state, action):\n",
    "    states_track[tuple(state)][tuple(action)] = []    #this is an array which will have appended values of that state-action pair for every 2000th episode   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1654336753950,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "kTrsJUSI5P_C"
   },
   "outputs": [],
   "source": [
    "# This function will append latest Q-values of the 6 Q-values which are being tracked for checking convergence\n",
    "def save_tracking_states(agent):\n",
    "    for state in states_track.keys():\n",
    "        for action in states_track[state].keys():\n",
    "            Q = agent.prediction(state, [action])\n",
    "            states_track[state][action].extend(Q)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1654336753951,
     "user": {
      "displayName": "Mangesh Joshi",
      "userId": "13098781678719992811"
     },
     "user_tz": -330
    },
    "id": "wTS5h3hZ5P_D"
   },
   "outputs": [],
   "source": [
    "#Defining a function to save the object as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hhhoa4uo5P_D",
    "outputId": "500e572b-edb0-4436-92e6-972f42c271a8"
   },
   "outputs": [],
   "source": [
    "initializeModel = True\n",
    "\n",
    "numData = 200\n",
    "\n",
    "episodeStart = 0\n",
    "numEpisodes = 200 * 30\n",
    "currentEpisode = episodeStart;\n",
    "\n",
    "for i in range(0, numData):     \n",
    "    num_states_tracked = 0\n",
    "\n",
    "    # reset epsilon start value and memory for each new configuration but keep the model parameters\n",
    "    # learned from the previous configuration\n",
    "    agent.reset()\n",
    "    \n",
    "    for episode in range(currentEpisode, numEpisodes):\n",
    "\n",
    "        # tracking total rewards, step count\n",
    "        tot_reward = 0\n",
    "        step_count = 0\n",
    "\n",
    "        #Reset the environment/Clear the previous states\n",
    "        env.reset()\n",
    "        env.initialize(pointData[i])  \n",
    "        \n",
    "        if initializeModel:\n",
    "            agent.initializeModel(env)\n",
    "            initializeModel = False\n",
    "\n",
    "        _, state = env.getStartState()\n",
    "        terminal_state = False\n",
    "\n",
    "        while not terminal_state:\n",
    "\n",
    "            #Get the free edge from the list\n",
    "            edgeToProcess = env.getEdgesToProcess()[0]\n",
    "                        \n",
    "            action, epsilon = agent.get_action(state, edgeToProcess, episode)            \n",
    "            \n",
    "            reward = env.getReward(edgeToProcess, action)        \n",
    "            next_state = env.getNextState(edgeToProcess, action)\n",
    "            env.removeProcessedEdge(edgeToProcess)\n",
    "            terminal_state = env.isTerminalState()\n",
    "            \n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            agent.append_sample(state, action, reward, next_state, terminal_state)\n",
    "            \n",
    "            # every time step do the training\n",
    "            agent.train_model()\n",
    "            tot_reward += reward\n",
    "            state = next_state\n",
    "            step_count += 1\n",
    "            if terminal_state:\n",
    "                # every episode update the target model to be same with model\n",
    "                agent.update_target_model()\n",
    "                \n",
    "            if reward > 0 and num_states_tracked < 3:\n",
    "                initialise_tracking_states(state, action)\n",
    "                save_tracking_states(agent)\n",
    "                num_states_tracked += 1\n",
    "\n",
    "            # Store the rewards\n",
    "            if terminal_state and episode % 5 ==0:\n",
    "                avg_reward.append(tot_reward/step_count)\n",
    "                total_reward.append(tot_reward)\n",
    "                print(\"pt Idx: \", i, \"epi:\", episode, \"  score:\", tot_reward, \"  eps:\", epsilon)\n",
    "                \n",
    "        if episode % 100 == 0:\n",
    "            save_tracking_states(agent)  \n",
    "            \n",
    "        if episode % 100 == 0:\n",
    "            agent.save(\"./DDQN_Delaunay.h5\")\n",
    "        \n",
    "        if episode % 200 == 0: \n",
    "            save_obj(states_track,'DDQN_States_tracked')\n",
    "    \n",
    "        if episode % 1000 ==0 and episode !=0:\n",
    "            plt.plot(list(range(len(avg_reward))), avg_reward)\n",
    "            plt.show()\n",
    "            \n",
    "        if (episode % 30 == 0 and episode !=0):\n",
    "            currentEpisode = episode + 1           \n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSshVceWxMg5"
   },
   "outputs": [],
   "source": [
    "agent.save(\"./DDQN_Delaunay11.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEKe0yg0iaED"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVeiJwrx5P_E"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key, value in states_track.items():\n",
    "    if i > 3:\n",
    "        break\n",
    "    print(i)\n",
    "    print(key)\n",
    "    print (value)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jUu3sg15P_F"
   },
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(243)\n",
    "plt.plot(xaxis,np.asarray(states_track[(0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0)][(0.09713178, 0.03444608, 0.27692298, 0.31709948, 0.03183285, 0.69482862, 0.6636030812134588, 0.4502759987258443, 0.33498928360322217, 1.9994953259621464, 0.4770073601791655, 0.6650899674484811, 0.14578541589254831)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mArFfF9T7Qpy"
   },
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(243)\n",
    "plt.plot(xaxis,np.asarray(states_track[(0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0)][(0.03054095, 0.60986665, 0.74407426, 0.61766639, 0.90472224, 0.57672152, 0.8748094234910715, 0.16578376234540373, 0.7135759387925181, 2.8811019884903466, 0.21166247836746213, 0.04882818673198578, 0.6564147570506149)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzRogfX9_JQ2"
   },
   "outputs": [],
   "source": [
    "print(states_track[(0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0)][(0.01843548, 0.67035792, 0.23844991, 0.16435803, 0.20708608, 0.10072192, 0.600061847959325, 0.07094536156931612, 0.5517628458751431, 2.2735202084796864, 0.7777300507851074, 0.09034239432499701, 0.6695466770829864)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzqDsIc8Uni5"
   },
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "\n",
    "\n",
    "xaxis = np.asarray(range(154))\n",
    "plt.subplot(243)\n",
    "plt.plot(xaxis,np.asarray(states_track[(0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0)][(0.01843548, 0.67035792, 0.23844991, 0.16435803, 0.20708608, 0.10072192, 0.600061847959325, 0.07094536156931612, 0.5517628458751431, 2.2735202084796864, 0.7777300507851074, 0.09034239432499701, 0.6695466770829864)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k72MNQSo1QTC"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(avg_reward))), avg_reward)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DTDoubleDQNMain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
